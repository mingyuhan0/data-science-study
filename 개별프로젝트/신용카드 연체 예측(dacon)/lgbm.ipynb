{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "QEJNi2ZyWbV9",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e2e1df8a-2d9d-43e7-f3a3-eb9c1cb1cf3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\admin\\anaconda3\\lib\\site-packages (from optuna) (6.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from optuna) (1.20.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from optuna) (1.3.1)\n",
      "Requirement already satisfied: alembic in c:\\users\\admin\\anaconda3\\lib\\site-packages (from optuna) (1.7.1)\n",
      "Requirement already satisfied: scipy!=1.4.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from optuna) (1.2.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\lib\\site-packages (from optuna) (4.31.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from optuna) (21.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\admin\\anaconda3\\lib\\site-packages (from optuna) (5.1)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: cliff in c:\\users\\admin\\anaconda3\\lib\\site-packages (from optuna) (3.9.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (2.3.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\admin\\anaconda3\\lib\\site-packages (from alembic->optuna) (4.8.1)\n",
      "Requirement already satisfied: Mako in c:\\users\\admin\\anaconda3\\lib\\site-packages (from alembic->optuna) (1.1.5)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\admin\\anaconda3\\lib\\site-packages (from alembic->optuna) (5.2.2)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cliff->optuna) (2.2.0)\n",
      "Requirement already satisfied: autopage>=0.4.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cliff->optuna) (0.4.0)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cliff->optuna) (2.1.2)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cliff->optuna) (5.6.0)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cliff->optuna) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.0)\n",
      "Requirement already satisfied: pyreadline in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (2.1)\n",
      "Requirement already satisfied: pyperclip>=1.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.1.7)\n",
      "Requirement already satisfied: attrs>=16.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (19.1.0)\n",
      "Requirement already satisfied: colorama>=0.3.7 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.4.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from importlib-metadata->alembic->optuna) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from Mako->alembic->optuna) (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yKgqJC_OxsJE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings, random\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6N_Hqh6cxx3Z"
   },
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rejtll0KyUaX"
   },
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "# 1. 결측치 처리\n",
    "\n",
    "train.fillna('NaN', inplace=True) \n",
    "test.fillna('NaN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6m4WS1gDyZAN"
   },
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "# 2. 이상치 처리\n",
    "# train['family_size'] > 7 인 데이터 제거\n",
    "\n",
    "train = train[(train['family_size'] <= 7)]\n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6NZgxHbzybAX"
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# 1. 의미없는 변수 제거\n",
    "# index 제거\n",
    "# FLAG_MOBIL 삭제:모든 값이 1로 동일\n",
    "\n",
    "train.drop(['index', 'FLAG_MOBIL'], axis=1, inplace=True)\n",
    "test.drop(['index', 'FLAG_MOBIL'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrWT_XJAyc2Q"
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# 2. DAYS_EMPLOYED\n",
    "# 양수인 데이터는 현재 무직자로 판단, 0 처리\n",
    "\n",
    "train['DAYS_EMPLOYED'] = train['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MwGqegXkyfCw"
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# 3. DAYS_BIRTH, begin_month, DAYS_EMPLOYED\n",
    "# 음수값 -> 양수 변환\n",
    "\n",
    "feats = ['DAYS_BIRTH', 'begin_month', 'DAYS_EMPLOYED']\n",
    "for feat in feats:\n",
    "    train[feat]=np.abs(train[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQJpwTTGygPt"
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# 4. 파생변수\n",
    "# numeric 변수는 최대한 다양한 특징을 보일 수 있도록 생성\n",
    "# category 변수는 여러가지를 조합해 보았지만 전체 변수를 합친 ID 하나만 만들었을때 가장 logloss가 낮음\n",
    "\n",
    "\n",
    "for df in [train, test]:\n",
    "    # before_EMPLOYED: 고용되기 전까지의 일수\n",
    "    df['before_EMPLOYED'] = df['DAYS_BIRTH'] - df['DAYS_EMPLOYED']\n",
    "    df['income_total_befofeEMP_ratio'] = df['income_total'] / df['before_EMPLOYED']\n",
    "    df['before_EMPLOYED_m'] = np.floor(df['before_EMPLOYED'] / 30) - ((np.floor(df['before_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "    df['before_EMPLOYED_w'] = np.floor(df['before_EMPLOYED'] / 7) - ((np.floor(df['before_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "    \n",
    "    #DAYS_BIRTH 파생변수- Age(나이), 태어난 월, 태어난 주(출생연도의 n주차)\n",
    "    df['Age'] = df['DAYS_BIRTH'] // 365\n",
    "    df['DAYS_BIRTH_m'] = np.floor(df['DAYS_BIRTH'] / 30) - ((np.floor(df['DAYS_BIRTH'] / 30) / 12).astype(int) * 12)\n",
    "    df['DAYS_BIRTH_w'] = np.floor(df['DAYS_BIRTH'] / 7) - ((np.floor(df['DAYS_BIRTH'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "    \n",
    "    #DAYS_EMPLOYED_m 파생변수- EMPLOYED(근속연수), DAYS_EMPLOYED_m(고용된 달) ,DAYS_EMPLOYED_w(고용된 주(고용연도의 n주차))  \n",
    "    df['EMPLOYED'] = df['DAYS_EMPLOYED'] // 365\n",
    "    df['DAYS_EMPLOYED_m'] = np.floor(df['DAYS_EMPLOYED'] / 30) - ((np.floor(df['DAYS_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "    df['DAYS_EMPLOYED_w'] = np.floor(df['DAYS_EMPLOYED'] / 7) - ((np.floor(df['DAYS_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "    #ability: 소득/(살아온 일수+ 근무일수)\n",
    "    df['ability'] = df['income_total'] / (df['DAYS_BIRTH'] + df['DAYS_EMPLOYED'])\n",
    "    \n",
    "    #income_mean: 소득/ 가족 수\n",
    "    df['income_mean'] = df['income_total'] / df['family_size']\n",
    "    \n",
    "    #ID 생성: 각 컬럼의 값들을 더해서 고유한 사람을 파악(*한 사람이 여러 개 카드를 만들 가능성을 고려해 begin_month는 제외함)\n",
    "    df['ID'] = \\\n",
    "    df['child_num'].astype(str) + '_' + df['income_total'].astype(str) + '_' +\\\n",
    "    df['DAYS_BIRTH'].astype(str) + '_' + df['DAYS_EMPLOYED'].astype(str) + '_' +\\\n",
    "    df['work_phone'].astype(str) + '_' + df['phone'].astype(str) + '_' +\\\n",
    "    df['email'].astype(str) + '_' + df['family_size'].astype(str) + '_' +\\\n",
    "    df['gender'].astype(str) + '_' + df['car'].astype(str) + '_' +\\\n",
    "    df['reality'].astype(str) + '_' + df['income_type'].astype(str) + '_' +\\\n",
    "    df['edu_type'].astype(str) + '_' + df['family_type'].astype(str) + '_' +\\\n",
    "    df['house_type'].astype(str) + '_' + df['occyp_type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_pRixV2uyioC"
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# 5. 파생변수와 다중공선을 보이는 컬럼 삭제\n",
    "\n",
    "cols = ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED',]\n",
    "train.drop(cols, axis=1, inplace=True)\n",
    "test.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qkW7FIEvykKz",
    "outputId": "6d972c2a-e3b6-4445-cf61-51c9fcbdeb81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Numerical features:  18\n",
      "Number of Categorical features:  9\n"
     ]
    }
   ],
   "source": [
    "# Scaling, Encoding\n",
    "# 1. Numeric, Category 컬럼 분류\n",
    "\n",
    "numerical_feats = train.dtypes[train.dtypes != \"object\"].index.tolist()\n",
    "numerical_feats.remove('credit')\n",
    "\n",
    "categorical_feats = train.dtypes[train.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "print(\"Number of Numerical features: \", len(numerical_feats))\n",
    "print(\"Number of Categorical features: \", len(categorical_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oBfZd6aIylYC"
   },
   "outputs": [],
   "source": [
    "# Scaling, Encoding\n",
    "# 2. Log Scale + 개별 feature 또는 target의 분포가 왜곡이 심할 경우 로그변환\n",
    "# income_total\n",
    "\n",
    "for df in [train,test]:\n",
    "    df['income_total'] = np.log1p(1+df['income_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ghRFdnUly3d1"
   },
   "outputs": [],
   "source": [
    "# Scaling, Encoding\n",
    "# 5. StandardScale\n",
    "# 이미 로그변환을 진행한 income_total을 제외한 나머지 numeric 컬럼 정규화\n",
    "\n",
    "numerical_feats.remove('income_total')\n",
    "scaler = StandardScaler()\n",
    "train[numerical_feats] = scaler.fit_transform(train[numerical_feats])\n",
    "test[numerical_feats] = scaler.transform(test[numerical_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agWtaSyiyOBh"
   },
   "outputs": [],
   "source": [
    "object_col = []\n",
    "for col in train.columns:\n",
    "    if train[col].dtype == 'object':\n",
    "        object_col.append(col)\n",
    "\n",
    "object_col2 = []\n",
    "for col2 in test.columns:\n",
    "    if test[col2].dtype == 'object':\n",
    "        object_col2.append(col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBufGjxV62Wt",
    "outputId": "0eba8b2e-f574-4059-caa2-4fbe4afc5972"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['gender',\n",
       "  'car',\n",
       "  'reality',\n",
       "  'income_type',\n",
       "  'edu_type',\n",
       "  'family_type',\n",
       "  'house_type',\n",
       "  'occyp_type',\n",
       "  'ID'],\n",
       " ['gender',\n",
       "  'car',\n",
       "  'reality',\n",
       "  'income_type',\n",
       "  'edu_type',\n",
       "  'family_type',\n",
       "  'house_type',\n",
       "  'occyp_type',\n",
       "  'ID'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_col, object_col2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3eopfptZ40e7"
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(train.loc[:,object_col])\n",
    "\n",
    "train_onehot_df = pd.DataFrame(enc.transform(train.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "train.drop(object_col, axis=1, inplace=True)\n",
    "train = pd.concat([train, train_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpwDkAuE4_gD"
   },
   "outputs": [],
   "source": [
    "enc2 = OneHotEncoder()\n",
    "enc2.fit(test.loc[:,object_col2])\n",
    "\n",
    "test_onehot_df = pd.DataFrame(enc2.transform(test.loc[:,object_col2]).toarray(), \n",
    "             columns=enc2.get_feature_names(object_col2))\n",
    "test.drop(object_col2, axis=1, inplace=True)\n",
    "test = pd.concat([test, test_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZh1ZumS8KrS",
    "outputId": "26c157f9-5c2e-42a5-f33a-247d833e2a0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26451, 8821), (10000, 5649))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FuxLr8MmXXez"
   },
   "outputs": [],
   "source": [
    "X = train\n",
    "y = train['credit']\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLhfdaYvDiuy",
    "outputId": "12a7d5b2-56a6-473b-9e99-9e40e1573c51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================1============================================\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.646294\tvalid_1's multi_logloss: 0.748779\n",
      "[200]\ttraining's multi_logloss: 0.563033\tvalid_1's multi_logloss: 0.72888\n",
      "[300]\ttraining's multi_logloss: 0.500858\tvalid_1's multi_logloss: 0.721748\n",
      "[400]\ttraining's multi_logloss: 0.449955\tvalid_1's multi_logloss: 0.719547\n",
      "Early stopping, best iteration is:\n",
      "[390]\ttraining's multi_logloss: 0.454545\tvalid_1's multi_logloss: 0.719269\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================2============================================\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.64864\tvalid_1's multi_logloss: 0.749833\n",
      "[200]\ttraining's multi_logloss: 0.56114\tvalid_1's multi_logloss: 0.728638\n",
      "[300]\ttraining's multi_logloss: 0.497265\tvalid_1's multi_logloss: 0.720354\n",
      "[400]\ttraining's multi_logloss: 0.448083\tvalid_1's multi_logloss: 0.718603\n",
      "Early stopping, best iteration is:\n",
      "[387]\ttraining's multi_logloss: 0.453519\tvalid_1's multi_logloss: 0.718182\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================3============================================\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.648076\tvalid_1's multi_logloss: 0.747393\n",
      "[200]\ttraining's multi_logloss: 0.562147\tvalid_1's multi_logloss: 0.732198\n",
      "[300]\ttraining's multi_logloss: 0.497172\tvalid_1's multi_logloss: 0.726561\n",
      "Early stopping, best iteration is:\n",
      "[281]\ttraining's multi_logloss: 0.508198\tvalid_1's multi_logloss: 0.726139\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================4============================================\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.652553\tvalid_1's multi_logloss: 0.747233\n",
      "[200]\ttraining's multi_logloss: 0.565815\tvalid_1's multi_logloss: 0.72405\n",
      "[300]\ttraining's multi_logloss: 0.503034\tvalid_1's multi_logloss: 0.715682\n",
      "[400]\ttraining's multi_logloss: 0.449932\tvalid_1's multi_logloss: 0.711411\n",
      "Early stopping, best iteration is:\n",
      "[389]\ttraining's multi_logloss: 0.455008\tvalid_1's multi_logloss: 0.711284\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================5============================================\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.652786\tvalid_1's multi_logloss: 0.74371\n",
      "[200]\ttraining's multi_logloss: 0.566596\tvalid_1's multi_logloss: 0.724932\n",
      "[300]\ttraining's multi_logloss: 0.502198\tvalid_1's multi_logloss: 0.716908\n",
      "[400]\ttraining's multi_logloss: 0.449404\tvalid_1's multi_logloss: 0.714802\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttraining's multi_logloss: 0.443747\tvalid_1's multi_logloss: 0.714625\n",
      "================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분리는 StratifiedKFold 를 사용하여 y값 분포를 비슷하게 분리시킴. -> 5-fold\n",
    "# lightgbm의 default parameter로 훈련.\n",
    "# 30번 이상 개선 없을 경우 중단.\n",
    "# 각 5개의 fold를 훈련하여 저장\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds=[]\n",
    "for train_idx, valid_idx in skf.split(train, train['credit']):\n",
    "    folds.append((train_idx, valid_idx))\n",
    "\n",
    "random.seed(42)\n",
    "lgb_models={}\n",
    "for fold in range(5):\n",
    "    print(f'===================================={fold+1}============================================')\n",
    "    train_idx, valid_idx = folds[fold]\n",
    "    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
    "                                         train['credit'][train_idx].values, train['credit'][valid_idx].values \n",
    "    lgb = LGBMClassifier(n_estimators=1000)\n",
    "    lgb.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
    "            early_stopping_rounds=30,\n",
    "           verbose=100)\n",
    "    lgb_models[fold]=lgb\n",
    "    print(f'================================================================================\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "te5oh9GaWNuy"
   },
   "outputs": [],
   "source": [
    "#optuna 활용한 최적 하이퍼파라미터 서치\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def objective(trial: Trial) -> float:\n",
    "    params_lgb = {\n",
    "        \"random_state\": 42,\n",
    "        \"verbosity\": -1,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"n_estimators\": 10000,\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 3e-5),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 9e-2),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 20),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.3, 1.0),\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 10),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 500),\n",
    "    }\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    model = LGBMClassifier(**params_lgb)\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    lgb_pred = model.predict_proba(X_valid)\n",
    "    log_score = log_loss(y_valid, lgb_pred)\n",
    "    \n",
    "    return log_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9yvGnHmMWNuy",
    "outputId": "9d8a41f1-358f-44b7-8b36-5cb6244fd308"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-31 08:40:55,039]\u001b[0m A new study created in memory with name: lgbm_parameter_opt\u001b[0m\n",
      "\u001b[32m[I 2021-08-31 08:41:38,908]\u001b[0m Trial 0 finished with value: 2.3942080329035147e-07 and parameters: {'reg_alpha': 1.12424581642324e-05, 'reg_lambda': 0.08556428806974939, 'max_depth': 15, 'num_leaves': 154, 'colsample_bytree': 0.4936111842654619, 'subsample': 0.40919616423534183, 'subsample_freq': 1, 'min_child_samples': 88, 'max_bin': 380}. Best is trial 0 with value: 2.3942080329035147e-07.\u001b[0m\n",
      "\u001b[32m[I 2021-08-31 08:41:59,011]\u001b[0m Trial 1 finished with value: 3.208155335351996e-07 and parameters: {'reg_alpha': 2.1245096608103405e-05, 'reg_lambda': 0.0018526142807772773, 'max_depth': 20, 'num_leaves': 214, 'colsample_bytree': 0.5274034664069657, 'subsample': 0.42727747704497043, 'subsample_freq': 2, 'min_child_samples': 34, 'max_bin': 357}. Best is trial 0 with value: 2.3942080329035147e-07.\u001b[0m\n",
      "\u001b[32m[I 2021-08-31 08:42:21,521]\u001b[0m Trial 2 finished with value: 1.5601276805653721e-07 and parameters: {'reg_alpha': 1.2964031109077052e-05, 'reg_lambda': 0.02621062970553237, 'max_depth': 13, 'num_leaves': 37, 'colsample_bytree': 0.5752867891211308, 'subsample': 0.5564532903055841, 'subsample_freq': 5, 'min_child_samples': 80, 'max_bin': 260}. Best is trial 2 with value: 1.5601276805653721e-07.\u001b[0m\n",
      "\u001b[32m[I 2021-08-31 08:43:08,731]\u001b[0m Trial 3 finished with value: 2.289216677553373e-07 and parameters: {'reg_alpha': 1.5431890808024213e-05, 'reg_lambda': 0.05331731527343814, 'max_depth': 1, 'num_leaves': 156, 'colsample_bytree': 0.502314474212375, 'subsample': 0.3455361150896956, 'subsample_freq': 10, 'min_child_samples': 97, 'max_bin': 443}. Best is trial 2 with value: 1.5601276805653721e-07.\u001b[0m\n",
      "\u001b[32m[I 2021-08-31 08:43:30,542]\u001b[0m Trial 4 finished with value: 1.7472244366551412e-07 and parameters: {'reg_alpha': 9.145366937509386e-06, 'reg_lambda': 0.008790499283853408, 'max_depth': 14, 'num_leaves': 114, 'colsample_bytree': 0.47322294090686734, 'subsample': 0.6466238370778892, 'subsample_freq': 1, 'min_child_samples': 92, 'max_bin': 277}. Best is trial 2 with value: 1.5601276805653721e-07.\u001b[0m\n",
      "\u001b[32m[I 2021-08-31 08:43:59,781]\u001b[0m Trial 5 finished with value: 1.0586710181403645e-07 and parameters: {'reg_alpha': 1.987904330777592e-05, 'reg_lambda': 0.028054003730936226, 'max_depth': 11, 'num_leaves': 141, 'colsample_bytree': 0.5109126733153162, 'subsample': 0.9787092394351908, 'subsample_freq': 8, 'min_child_samples': 95, 'max_bin': 469}. Best is trial 5 with value: 1.0586710181403645e-07.\u001b[0m\n",
      "\u001b[32m[I 2021-08-31 08:44:41,081]\u001b[0m Trial 6 finished with value: 1.6500069931074103e-07 and parameters: {'reg_alpha': 1.7941020364544445e-05, 'reg_lambda': 0.08296868193333816, 'max_depth': 2, 'num_leaves': 51, 'colsample_bytree': 0.4271363733463229, 'subsample': 0.527731231534285, 'subsample_freq': 4, 'min_child_samples': 31, 'max_bin': 449}. Best is trial 5 with value: 1.0586710181403645e-07.\u001b[0m\n",
      "\u001b[32m[I 2021-08-31 08:44:57,296]\u001b[0m Trial 7 finished with value: 2.49473159449575e-07 and parameters: {'reg_alpha': 1.0709032267540741e-05, 'reg_lambda': 0.025284113062519174, 'max_depth': 11, 'num_leaves': 37, 'colsample_bytree': 0.8813181884524238, 'subsample': 0.35218545057583955, 'subsample_freq': 10, 'min_child_samples': 79, 'max_bin': 259}. Best is trial 5 with value: 1.0586710181403645e-07.\u001b[0m\n",
      "\u001b[32m[I 2021-08-31 08:45:23,702]\u001b[0m Trial 8 finished with value: 2.648397984835009e-07 and parameters: {'reg_alpha': 1.7560829253683595e-07, 'reg_lambda': 0.07339153040632079, 'max_depth': 15, 'num_leaves': 187, 'colsample_bytree': 0.8627622080115674, 'subsample': 0.35183125621386324, 'subsample_freq': 4, 'min_child_samples': 16, 'max_bin': 459}. Best is trial 5 with value: 1.0586710181403645e-07.\u001b[0m\n",
      "\u001b[32m[I 2021-08-31 08:45:46,430]\u001b[0m Trial 9 finished with value: 1.0374241295932559e-07 and parameters: {'reg_alpha': 1.8702710823558463e-05, 'reg_lambda': 0.02978082892775818, 'max_depth': 2, 'num_leaves': 81, 'colsample_bytree': 0.5951099932160482, 'subsample': 0.8107243248366449, 'subsample_freq': 7, 'min_child_samples': 90, 'max_bin': 342}. Best is trial 9 with value: 1.0374241295932559e-07.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 1.0374241295932559e-07\n",
      "Best trial: {'reg_alpha': 1.8702710823558463e-05, 'reg_lambda': 0.02978082892775818, 'max_depth': 2, 'num_leaves': 81, 'colsample_bytree': 0.5951099932160482, 'subsample': 0.8107243248366449, 'subsample_freq': 7, 'min_child_samples': 90, 'max_bin': 342}\n"
     ]
    }
   ],
   "source": [
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(\n",
    "    study_name=\"lgbm_parameter_opt\",\n",
    "    direction=\"minimize\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "study.optimize(objective, n_trials=10)\n",
    "print(\"Best Score:\", study.best_value)\n",
    "print(\"Best trial:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocou5vENabUQ",
    "outputId": "e85fc26d-a0fb-482a-c8ac-32ec2316aded"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================1============================================\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.795518\tvalid_1's multi_logloss: 0.801544\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.795518\tvalid_1's multi_logloss: 0.801544\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================2============================================\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.794634\tvalid_1's multi_logloss: 0.806062\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.794634\tvalid_1's multi_logloss: 0.806062\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================3============================================\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.79494\tvalid_1's multi_logloss: 0.803668\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.79494\tvalid_1's multi_logloss: 0.803668\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================4============================================\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.794436\tvalid_1's multi_logloss: 0.804607\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.794436\tvalid_1's multi_logloss: 0.804607\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================5============================================\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.796103\tvalid_1's multi_logloss: 0.798463\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.796103\tvalid_1's multi_logloss: 0.798463\n",
      "================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# optuna로 도출한 최적 파라미터 적용\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds=[]\n",
    "for train_idx, valid_idx in skf.split(train, train['credit']):\n",
    "    folds.append((train_idx, valid_idx))\n",
    "\n",
    "random.seed(42)\n",
    "lgb_models={}\n",
    "for fold in range(5):\n",
    "    print(f'===================================={fold+1}============================================')\n",
    "    train_idx, valid_idx = folds[fold]\n",
    "    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
    "                                         train['credit'][train_idx].values, train['credit'][valid_idx].values \n",
    "    lgb = LGBMClassifier(reg_alpha= 1.8702710823558463e-05, \n",
    "                         reg_lambda= 0.02978082892775818, \n",
    "                         max_depth= 2, \n",
    "                         num_leaves= 81, \n",
    "                         colsample_bytree= 0.5951099932160482, \n",
    "                         subsample= 0.8107243248366449, \n",
    "                         subsample_freq= 7, \n",
    "                         min_child_samples= 90, \n",
    "                         max_bin= 342)\n",
    "    lgb.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
    "            early_stopping_rounds=30,\n",
    "           verbose=100)\n",
    "    lgb_models[fold]=lgb\n",
    "    print(f'================================================================================\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lgbm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
